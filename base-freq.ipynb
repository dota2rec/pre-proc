{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "# transform two dict to feature vector\n",
    "def dict_to_vec(dic1, dic2):\n",
    "    kvec=[]\n",
    "    vec1=[]\n",
    "    for k, v in dic1.iteritems():\n",
    "        kvec.append(k)\n",
    "        vec1.append(v)\n",
    "    vec2=[0]*len(kvec)\n",
    "    for k, v in dic2.iteritems():\n",
    "        if k in kvec:\n",
    "            index=kvec.index(k)\n",
    "            if v==None:\n",
    "                v=0\n",
    "            vec2[index]=v\n",
    "        else:\n",
    "            kvec.append(k)\n",
    "            vec1.append(0)\n",
    "            vec2.append(v)\n",
    "    return vec1, vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items continuous id assignment success!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# validate the dict data for hero and item\n",
    "def validate(data):\n",
    "    id=[]\n",
    "    for key in data:\n",
    "        tid=data[key]\n",
    "        id.append(tid)\n",
    "    id.sort();\n",
    "    flag=True\n",
    "    for i in range(0, len(id)):\n",
    "        if id[i]!=i:\n",
    "            print i\n",
    "            flag=False\n",
    "    #print id\n",
    "    return flag\n",
    "# get the key-id pairs of hero or item data dict to be continuous\n",
    "def continuous_format(data):\n",
    "    i=0\n",
    "    for key in data:\n",
    "        data[key]=i\n",
    "        i+=1\n",
    "\n",
    "# construct item/hero-id based on json data\n",
    "# reformat the id sequence\n",
    "def dict_from_json(data, reindex):\n",
    "    dict_data=dict()\n",
    "    repeat=0\n",
    "    for i in range(0, len(data)):\n",
    "        #name=data[i]['name']\n",
    "        name=re.sub('(npc_dota_hero_|item_)', '', data[i]['name'])\n",
    "        #name=re.sub('[npc_|item_]', '', data[i]['name'])\n",
    "        if name not in dict_data:\n",
    "            if reindex:\n",
    "                dict_data[name]=(i-repeat)\n",
    "            else:\n",
    "                dict_data[name]=int(data[i]['id'])\n",
    "        else:\n",
    "            repeat+=1\n",
    "            \n",
    "        \n",
    "    return dict_data\n",
    "\n",
    "# for a up-to-date item/hero list, we can http request to\n",
    "# https://api.opendota.com/api/explorer?sql=SELECT%20*%20FROM%20items\n",
    "heroes=json.load(open('heroes.json'))['rows']\n",
    "items=json.load(open('items.json'))['rows']\n",
    "#print heroes\n",
    "heroes=dict_from_json(heroes, False)\n",
    "items=dict_from_json(items, True)\n",
    "\n",
    "#if validate(heroes):\n",
    "#    print \"heroes continuous id assignment success!\"\n",
    "if validate(items):\n",
    "    print \"items continuous id assignment success!\"\n",
    "#print items\n",
    "#print heroes\n",
    "#print items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hero count: 121\n",
      "item count: 292\n"
     ]
    }
   ],
   "source": [
    "# based on the google drive data\n",
    "# hero count=113\n",
    "# item count=1020\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "fpath='./data/'\n",
    "\n",
    "# init some coefficients\n",
    "# the baseline freq coefficient\n",
    "a=1.2\n",
    "b=0.8\n",
    "\n",
    "# init basic hero-item freq matrix\n",
    "\n",
    "def maxValInDict(data):\n",
    "    maxval=(-sys.maxint-1)\n",
    "    for key in data:\n",
    "        if data[key]>maxval:\n",
    "            maxval=data[key]\n",
    "    return maxval\n",
    "\n",
    "hcount=maxValInDict(heroes)+1\n",
    "icount=len(items)\n",
    "print \"hero count: \" + str(hcount)\n",
    "print \"item count: \" + str(icount)\n",
    "basic_freq=[]\n",
    "for i in range(0, hcount):\n",
    "    basic_freq.append([0]*icount)\n",
    "\n",
    "# load from data and computer base freq\n",
    "# the first five heroes in the players list is radiant\n",
    "for fname in os.listdir(fpath):\n",
    "    data=json.load(open(fpath+fname))\n",
    "    players=data['players']\n",
    "    for i in range(0, len(players)):\n",
    "        player=players[i]\n",
    "        heroid=player['hero_id']\n",
    "        purchase=player['purchase']\n",
    "        if player['isRadiant']:\n",
    "            win=player['radiant_win']\n",
    "        else:\n",
    "            win=(not player['radiant_win'])\n",
    "        # be noticed that purchase is a dictionary\n",
    "        for key in purchase:\n",
    "            iid=items[key]\n",
    "            try:\n",
    "                if win: \n",
    "                    basic_freq[heroid][iid]+=a\n",
    "                else: \n",
    "                    basic_freq[heroid][iid]+=b\n",
    "            except IndexError as e:\n",
    "                print \"file name: \" + fname\n",
    "                print \"item id: \" + str(iid)\n",
    "                print \"hero id: \" + str(heroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict based on model\n",
    "# the basic model is a matrix that contains weight \n",
    "# returns base h*k item recommendations\n",
    "import random\n",
    "from scipy import spatial as sp\n",
    "import numpy as np\n",
    "# if we do not consider time, rather we consider \n",
    "# all the necessary items in all time, then our method should also be effective\n",
    "# in this case we may recommend more items like 15-20 that captures early-mid-final \n",
    "# k can be determined following:\n",
    "# 1. get the avg total items throughout every match for every hero\n",
    "# 2. guess\n",
    "def base_rec(heroes, model, k):\n",
    "    res=[]\n",
    "    for h in heroes:\n",
    "        hifreq=model[h]\n",
    "        hifreq=hifreq.sort()\n",
    "        res.append(hifreq[0:k])\n",
    "\n",
    "# in matches won, recommend items, compute similarity with actual items\n",
    "# OR\n",
    "# in all games, find which side had items more similar to recommended, then compute winning percentage\n",
    "# calculate the similarity between item purchase log\n",
    "# per hero\n",
    "# assumes both lists are composed of item name\n",
    "# TODO: this may be extended by considering item purchase sequence\n",
    "def hero_purchase_sim_calc(list1, list2):\n",
    "    c1=Counter(list1)\n",
    "    c2=Counter(list2)\n",
    "    sim=cosine_similarity(c1, c2)\n",
    "    return sim\n",
    "\n",
    "# sim: similarity between item purchases\n",
    "# ideal evaluation: P(Exactly same purchase log) \n",
    "# @hp: actual hero-purchase counter dict array\n",
    "# @hp_rec: recommended hero-purchase counter dict array\n",
    "# @opt: aggregation function, average and etc\n",
    "# TODO: for diff heroes, we may have different weight when calc total similarity\n",
    "def team_purchase_sim_calc(hp, hp_rec, norm=False, aggr_opt='avg'):\n",
    "    sim_vec=[]\n",
    "    tot_sim=0\n",
    "    for (hp, hpr) in zip(hp, hp_rec):\n",
    "        hp, hpr=dict_to_vec(hp, hpr)\n",
    "        if norm:\n",
    "            norm1=np.linalg.norm(hp)\n",
    "            norm2=np.linalg.norm(hpr)\n",
    "            hp=hp/norm1\n",
    "            hpr=hpr/norm2\n",
    "        sim=sp.distance.cosine(hp, hpr)\n",
    "        sim_vec.append(sim)\n",
    "    if aggr_opt=='avg':\n",
    "        # the length should always be 5\n",
    "        assert(len(hp)==5)\n",
    "        tot_sim=sim_vec/len(hp)\n",
    "    else:\n",
    "        print \"no such aggr function is pre defined!\"\n",
    "        tot_sim=-1\n",
    "    return tot_sim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unnormalized: \n",
      "[2, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[3, 7, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 5, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n",
      "0.270101541292\n",
      "normalized: \n",
      "[ 0.27216553  0.54433105  0.13608276  0.13608276  0.13608276  0.27216553\n",
      "  0.13608276  0.27216553  0.13608276  0.13608276  0.13608276  0.13608276\n",
      "  0.13608276  0.13608276  0.54433105  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "[ 0.27272727  0.63636364  0.          0.          0.09090909  0.          0.\n",
      "  0.          0.          0.09090909  0.09090909  0.          0.09090909\n",
      "  0.09090909  0.45454545  0.09090909  0.09090909  0.09090909  0.09090909\n",
      "  0.09090909  0.27272727  0.09090909  0.09090909  0.09090909  0.09090909\n",
      "  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
      "  0.09090909  0.09090909  0.18181818  0.09090909  0.09090909  0.09090909]\n",
      "0.270101541292\n"
     ]
    }
   ],
   "source": [
    "# testing cosine similarity calculation\n",
    "from scipy import spatial as sp\n",
    "import numpy as np\n",
    "data=json.load(open('data/3803000030.json'))\n",
    "dict1=data['players'][0]['purchase']\n",
    "dict2=data['players'][1]['purchase']\n",
    "\n",
    "vec1, vec2=dict_to_vec(dict1, dict2)\n",
    "\n",
    "print \"unnormalized: \"\n",
    "print vec1\n",
    "print vec2\n",
    "sim=sp.distance.cosine(vec1, vec2)\n",
    "print sim\n",
    "\n",
    "print \"normalized: \"\n",
    "norm1=np.linalg.norm(vec1)\n",
    "norm2=np.linalg.norm(vec2)\n",
    "vec1=vec1/norm1\n",
    "vec2=vec2/norm2\n",
    "print vec1\n",
    "print vec2\n",
    "sim=sp.distance.cosine(vec1, vec2)\n",
    "print sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase: 15\tlog: 15\n",
      "keys not in purchase log: \n",
      "\n",
      "purchase: 31\tlog: 28\n",
      "keys not in purchase log: \n",
      "dust\n",
      "recipe_cyclone\n",
      "recipe_hand_of_midas\n",
      "\n",
      "purchase: 23\tlog: 21\n",
      "keys not in purchase log: \n",
      "dust\n",
      "recipe_yasha\n",
      "\n",
      "purchase: 22\tlog: 18\n",
      "keys not in purchase log: \n",
      "recipe_maelstrom\n",
      "recipe_hand_of_midas\n",
      "dust\n",
      "recipe_diffusal_blade\n",
      "\n",
      "purchase: 25\tlog: 22\n",
      "keys not in purchase log: \n",
      "dust\n",
      "recipe_diffusal_blade\n",
      "recipe_yasha\n",
      "\n",
      "purchase: 14\tlog: 12\n",
      "keys not in purchase log: \n",
      "recipe_soul_ring\n",
      "dust\n",
      "\n",
      "purchase: 21\tlog: 21\n",
      "keys not in purchase log: \n",
      "\n",
      "purchase: 37\tlog: 33\n",
      "keys not in purchase log: \n",
      "dust\n",
      "recipe_black_king_bar\n",
      "recipe_sange\n",
      "recipe_yasha\n",
      "\n",
      "purchase: 38\tlog: 33\n",
      "keys not in purchase log: \n",
      "recipe_manta\n",
      "dust\n",
      "recipe_wraith_band\n",
      "recipe_yasha\n",
      "recipe_force_staff\n",
      "\n",
      "purchase: 19\tlog: 17\n",
      "keys not in purchase log: \n",
      "recipe_force_staff\n",
      "ward_dispenser\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate difference between purchase_log and purchase\n",
    "data=json.load(open('data/3803000030.json'))\n",
    "exist=False\n",
    "for p in data['players']:\n",
    "    kdict=dict()\n",
    "    for i in p['purchase_log']:\n",
    "        key=i['key']\n",
    "        if key in kdict:\n",
    "            kdict[key]+=1\n",
    "        else:\n",
    "            kdict[key]=1\n",
    "    print \"purchase: \" + str(len(p['purchase'])) + \"\\tlog: \" + str(len(kdict))\n",
    "    print \"keys not in purchase log: \"\n",
    "    for key in p['purchase']:\n",
    "        if key not in kdict:\n",
    "            print key\n",
    "    print \"\"\n",
    "    #print \"keys not in purchase: \"\n",
    "    #for key in kdict:\n",
    "    #    if key not in p['purchase']:\n",
    "    #        print key\n",
    "    #        exist=True\n",
    "#print exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
